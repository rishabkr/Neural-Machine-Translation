# Neural-Machine-Translation
A comparison between Seq2Seq encoder decoder based NMT models with and without attention. The models have been trained only for 25 epochs, they can show much better BLEU scores when trained for longer periods. The BLEU score for NMT model without attention was 12.34 and NMT model WITH attention was 20.82. Transformer based models to be added soon.

If you have difficulty viewing any notebook please use <a href = "https://nbviewer.jupyter.org/" > this link </a> to view the notebooks.
